# Self Training Algorithm
## Abstract
Self training doesn't work because training on self sampled data tends to make a model worse.
Using data sampled from another model to train a model works.
This is convenient because the source model can be much larger than the training model, so the source model gets compressed.
The smaller learned model will be cheaper to host and will work on machines with less compute.

So, if you only have one model how do you train a model of equal size or larger?
It is proposed to sample from the model and then cluster the samples into sets.
Each set is then used to train a model.
The models are then sampled from in order to train a larger model.
## The Language Model
In this implementation a [Markov model](https://en.wikipedia.org/wiki/Markov_model) is used as the language model.
The Markov model is chosen because it trains very fast and inference is very fast.
[MCTS](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search) is used to find more probable strings.
## The Clustering Algorithm
The most probable strings are clustered using the Morpheus clustering algorithm.
For each string in the set of strings, the probability vectors of the strings are processed as follows:
`Statistics(PageRank(CosineSimilarity((X*S),(Y*S))))`
X and Y are random matrices samples from a Gaussian distribution, and S is a matrix of string probability vectors.
The covariance, standard deviation, and mean are the statistics which are calculated.
Meta kmeans is used to cluster the rows of the covariance matrix which correspond to the inputted strings.
Each cluster is then used to train a Markov model, and the entire process repeats several times.
## Example Generated Text
A final text is generated by combining the Markov models:
```
What is the meaning of life?

PROSPERO.
Music. YOU AGREEMEDIES OF THE
GRATIANO.
Full opinion.

YOUNG LEWIS BEFORE YOU AGREEMENT WITH HIS BEFORE YOU AGREEMEN

CHATILL NOTICE THIS MAN.
We arment,
And Edward you.

Enterject Gutenberg™ License, though.

CHAPTER 41. Comfiture!
[_Exeunt._]

RICHARLOTS ABROAD ***

TROILUS OF SYRACUSE.
Ay, and thy
size.......................................................................................................................................... Mr. God, ever.

ENOBARBUS.
[_To Warwick up some of leman, was motion
Crateful. Thou speak was; I have
I never at the meaning of life?”

Met I will nothing in the meaning of life-o-r-g-e J-a-x-o-n—

ANTIPHOLUS OF EPHESUS.
[_Exit Mesopotaminable
Shall the meaning of life?

BRABANTIPHOLUS OF ROI EST TREASON!”

QUEEN ELIZABETH.
How shackluyt, and your High; and they live
none.
                                          Richmond.

QUEEN MARGARETH TRIBUNES.
Naturesquel

CHIEF JUSTICE of the great fine elders.

RIC
```
# Future Work
- Mixture of experts (Markov models for each book), sample from each one and use the Morpheus algorithm to determine which one is the output.
- Use reinforcement learning with Markov models.
